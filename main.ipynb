{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNLoWz3Ghk4+EPmVN34AnGh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohsen-goodarzi/DeepSpeech-with-keras/blob/master/model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8TRpiGeWm84W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import layers\n",
        "from keras import models\n",
        "from keras import initializers\n",
        "from keras.activations import relu\n",
        "import keras.backend as K"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xgXFCVsPfPb-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def ctc_lambda_func(args):\n",
        "    labels, y_pred, input_length, label_length = args\n",
        "    return K.ctc_batch_cost(labels, y_pred, input_length, label_length)\n",
        "\n",
        "def clipped_relu(x):\n",
        "    return relu(x, max_value=20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swAWkXTlkJW2",
        "colab_type": "text"
      },
      "source": [
        "Create DeepSpeech 1 model with dropout:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "awRS00_Hjhu9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def DeepSpeech1(input_dim=26,output_dim=37,fc_size=1024, rnn_size=512,dropout=[0.1, 0.1, 0.1,0.1,0.1]):\n",
        "  init=initializers.random_normal(stddev=0.046875)\n",
        "\n",
        "  model=models.Sequential()\n",
        "  \n",
        "  #first 3 FC layers\n",
        "  model.add(layers.TimeDistributed(layers.Dense(fc_size,name='fc1',kernel_initializer=init,bias_initializer=init,activation=clipped_relu),input_shape=(None,input_dim)))\n",
        "  model.add(layers.TimeDistributed(layers.Dropout(dropout[0])))\n",
        "  model.add(layers.TimeDistributed(layers.Dense(fc_size,name='fc2',kernel_initializer=init,bias_initializer=init,activation=clipped_relu)))\n",
        "  model.add(layers.TimeDistributed(layers.Dropout(dropout[1])))\n",
        "  model.add(layers.TimeDistributed(layers.Dense(fc_size,name='fc3',kernel_initializer=init,bias_initializer=init,activation=clipped_relu)))\n",
        "  model.add(layers.TimeDistributed(layers.Dropout(dropout[2])))\n",
        "\n",
        "  # Layer 4: BiDirectional RNN\n",
        "  model.add(layers.Bidirectional(layers.LSTM(rnn_size,name='bilstm4',kernel_initializer=initializers.he_normal(),return_sequences=True,activation=relu, dropout=dropout[3]),merge_mode='sum'))\n",
        "\n",
        "  # Layer 5: FC\n",
        "  model.add(layers.TimeDistributed(layers.Dense(fc_size,name='fc5',kernel_initializer=init,bias_initializer=init,activation=clipped_relu)))\n",
        "  model.add(layers.TimeDistributed(layers.Dropout(dropout[4])))\n",
        "\n",
        "  # Layer 6: softmax output\n",
        "  model.add(layers.TimeDistributed(layers.Dense(output_dim,name='out',kernel_initializer=init,bias_initializer=init,activation='softmax')))\n",
        "\n",
        "  return model\n",
        "  \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_dHePkcFVOuw",
        "colab_type": "text"
      },
      "source": [
        "Add CTC loss:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fpL4hC3wVQ-3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def add_ctc(model_core):\n",
        "    input_data=model_core.inputs[0]\n",
        "    y_pred=model_core.outputs[0]\n",
        "\n",
        "    labels = layers.Input(name='the_labels', shape=(None,), dtype='int32')\n",
        "    input_length = layers.Input(name='input_length', shape=(1,), dtype='int32')\n",
        "    label_length = layers.Input(name='label_length', shape=(1,), dtype='int32')\n",
        "\n",
        "    loss_out = layers.Lambda(ctc_lambda_func, output_shape=(1,), name='ctc')([labels, y_pred, input_length, label_length])\n",
        "\n",
        "    model = models.Model(inputs=[input_data, labels, input_length, label_length], outputs=loss_out)\n",
        "\n",
        "    return model\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E05PgMxIVp6H",
        "colab_type": "code",
        "outputId": "568825a2-3aa3-4b40-d213-dcefc3b87198",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 706
        }
      },
      "source": [
        "core_model=DeepSpeech1()\n",
        "final_model= add_ctc(core_model)\n",
        "final_model.summary()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "time_distributed_118_input (Inp (None, None, 26)     0                                            \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_118 (TimeDistr (None, None, 1024)   27648       time_distributed_118_input[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_119 (TimeDistr (None, None, 1024)   0           time_distributed_118[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_120 (TimeDistr (None, None, 1024)   1049600     time_distributed_119[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_121 (TimeDistr (None, None, 1024)   0           time_distributed_120[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_122 (TimeDistr (None, None, 1024)   1049600     time_distributed_121[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_123 (TimeDistr (None, None, 1024)   0           time_distributed_122[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_14 (Bidirectional (None, None, 512)    6295552     time_distributed_123[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_124 (TimeDistr (None, None, 1024)   525312      bidirectional_14[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_125 (TimeDistr (None, None, 1024)   0           time_distributed_124[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "the_labels (InputLayer)         (None, None)         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_126 (TimeDistr (None, None, 37)     37925       time_distributed_125[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "input_length (InputLayer)       (None, 1)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "label_length (InputLayer)       (None, 1)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "ctc (Lambda)                    (None, 1)            0           the_labels[0][0]                 \n",
            "                                                                 time_distributed_126[0][0]       \n",
            "                                                                 input_length[0][0]               \n",
            "                                                                 label_length[0][0]               \n",
            "==================================================================================================\n",
            "Total params: 8,985,637\n",
            "Trainable params: 8,985,637\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
